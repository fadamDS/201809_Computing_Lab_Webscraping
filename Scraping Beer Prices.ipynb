{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Felix Adam - Computing Lab Assignment 2 -  Webscraping Beer Prices\n",
    "\n",
    "The goal of this notebook is to scrape current beer prices from a big german food delivery site. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import queue\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor,as_completed, wait, TimeoutError\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a class for scraping beer prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeerScraper:\n",
    "    \n",
    "    # Initializing with a starting URL,the queue and an empty list for results\n",
    "    def __init__(self,start_url, user_agent, friendly_scraping_time = 10):\n",
    "        \n",
    "        self.start_url = start_url\n",
    "        self.friendly_scraping_time = friendly_scraping_time\n",
    "        self.beer_list = []\n",
    "        self.user_agent = user_agent\n",
    "       \n",
    "    ## Get Beer List\n",
    "    def get_beer_list(self, log_info = False):\n",
    "        # Setting up the starting link\n",
    "        current_link = self.start_url\n",
    "    \n",
    "        # Initialising the while loop\n",
    "        no_more_pages = False\n",
    "\n",
    "        while no_more_pages == False:\n",
    "            \n",
    "            if log_info:\n",
    "                print(current_link + ' Sleeping for ' + str(self.friendly_scraping_time) + ' Seconds')\n",
    "    \n",
    "            # Gently scraping \n",
    "            time.sleep(self.friendly_scraping_time)\n",
    "            \n",
    "            if log_info:\n",
    "                print('Sleep done')\n",
    "            \n",
    "            # Setting Headers\n",
    "            headers = {'User-Agent': self.user_agent}\n",
    "            \n",
    "        \n",
    "            # Making request\n",
    "            beer_list_request = requests.get(current_link,headers = headers)\n",
    "    \n",
    "            beer_list_page = BeautifulSoup(beer_list_request.content, 'html.parser')\n",
    "    \n",
    "            # Get all beers on the page\n",
    "            beers = beer_list_page.find_all('div', class_= 'search-service-ProductTileContent')\n",
    "\n",
    "            # Appending all beers to the list \n",
    "            for beer in beers:\n",
    "                # Find URL of current beer\n",
    "                beer_url = 'https://shop.rewe.de'+beer.find('a')['href']\n",
    "                \n",
    "                # Put the beer in the queue \n",
    "                self.beer_list.append(beer_url)\n",
    "                \n",
    "            if log_info:\n",
    "                print('Total Nr. of Beers found: '+ str(len(self.beer_list)))\n",
    "    \n",
    "            # Find next link\n",
    "            next_link = beer_list_page.find_all('a', href = True, text ='>')\n",
    "\n",
    "            if len(next_link) == 0:\n",
    "                no_more_pages = True \n",
    "            else:\n",
    "                current_link = next_link[0]['href']\n",
    "    \n",
    "        print('Done')\n",
    "        \n",
    "    ### Method get_beer, scrapes single beer page ###\n",
    "    def get_beer(self,beer_url):\n",
    "        \n",
    "        # Setting Headers\n",
    "        headers = {'User-Agent': self.user_agent}\n",
    "         \n",
    "        # Getting Request\n",
    "        # Setting User Agent here as well\n",
    "        beer_page_request = requests.get(beer_url, headers = headers)\n",
    "        \n",
    "        # Parsing with beautiful soup\n",
    "        beer_parsed = BeautifulSoup(beer_page_request.content, 'html.parser')\n",
    "\n",
    "        # Title\n",
    "        beer_title = beer_parsed.find('h1', class_= 'pd-QuickInfo__heading' ).text\n",
    "\n",
    "        # Price, integer part\n",
    "        integer_price = beer_parsed.find('span', class_='pd-price__predecimal').text\n",
    "\n",
    "        # Price, decimal part, removing leading whitespace as well\n",
    "        decimal_price = beer_parsed.find('span', class_='pd-price__decimal').text.lstrip()\n",
    "\n",
    "        # Full Price, concat and convert to float\n",
    "        beer_price = float(integer_price+'.'+decimal_price)\n",
    "\n",
    "        #Get the info string\n",
    "        info_string = beer_parsed.find('div', class_='rs-qa-price-base pd-Grammage pd-Grammage--Detail').text\n",
    "        \n",
    "        if '=' not in info_string:\n",
    "            price_per_liter = 0\n",
    "        else:\n",
    "        \n",
    "            # Extract info inside of the brackets\n",
    "            price_per_liter_string = info_string[info_string.find(\"(\")+1:info_string.find(\")\")]\n",
    "\n",
    "            # Extract string left to the equal sign (e.g. 1 l = 2,17 € or 1 l = 2 €)\n",
    "            temp_price_liter = price_per_liter_string.split('=')[1]\n",
    "    \n",
    "            # Error handling for missing commas\n",
    "            if \",\" not in temp_price_liter:\n",
    "                price_per_liter = int(re.search(r'\\d+', temp_price_liter).group())\n",
    "\n",
    "            else:\n",
    "                # Get the integer \n",
    "                temp_price_liter_int  = temp_price_liter.split(',')[0]\n",
    "    \n",
    "                # Get the decimal\n",
    "                temp_price_liter_dec = temp_price_liter.split(',')[1].split(' ')[0]\n",
    "            \n",
    "                # Convert to price per liter\n",
    "                price_per_liter = float(temp_price_liter_int+'.'+temp_price_liter_dec)\n",
    "\n",
    "        \n",
    "        # Collect all the beer info in a list\n",
    "        beer = [beer_title, beer_price, price_per_liter] \n",
    "    \n",
    "        #Return the beer\n",
    "        return beer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had to cheat a little bit here, I already got blocked due to sending endless requests because of errors in the parrale threads\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36'\n",
    "\n",
    "# Initializing the Scraper with the start URL\n",
    "# Sleeping 1 min after every request. This kind of destroys the performance, however, I got blocked before being to fast.\n",
    "scraper = BeerScraper(start_url='https://shop.rewe.de/c/getraenke/?search=Bier', user_agent= user_agent, \n",
    "                      friendly_scraping_time= 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://shop.rewe.de/c/getraenke/?search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 40\n",
      "https://shop.rewe.de/c/getraenke/?page=2&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 80\n",
      "https://shop.rewe.de/c/getraenke/?page=3&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 120\n",
      "https://shop.rewe.de/c/getraenke/?page=4&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 160\n",
      "https://shop.rewe.de/c/getraenke/?page=5&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 200\n",
      "https://shop.rewe.de/c/getraenke/?page=6&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 240\n",
      "https://shop.rewe.de/c/getraenke/?page=7&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 280\n",
      "https://shop.rewe.de/c/getraenke/?page=8&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 320\n",
      "https://shop.rewe.de/c/getraenke/?page=9&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 360\n",
      "https://shop.rewe.de/c/getraenke/?page=10&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 400\n",
      "https://shop.rewe.de/c/getraenke/?page=11&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 440\n",
      "https://shop.rewe.de/c/getraenke/?page=12&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 480\n",
      "https://shop.rewe.de/c/getraenke/?page=13&search=Bier Sleeping for 60 Seconds\n",
      "Sleep done\n",
      "Total Nr. of Beers found: 502\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Getting all the webpages\n",
    "scraper.get_beer_list(log_info= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 13s, sys: 7.7 s, total: 3min 21s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "# Parallel scraping of all beers in the lis.\n",
    "\n",
    "%%time\n",
    "\n",
    "# Defining a worker \n",
    "def worker(i):\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if item == 'break':\n",
    "            break\n",
    "        results = scraper.get_beer(item)\n",
    "        r.append(results)\n",
    "        q.task_done()\n",
    "\n",
    "# Making a queue and results list\n",
    "q = queue.Queue()\n",
    "r = []\n",
    "for b in beer_list:\n",
    "    q.put(b)\n",
    "\n",
    "\n",
    "# Pooling workers to get all beers\n",
    "with ThreadPoolExecutor(50) as pool:\n",
    "    futures = pool.map(worker, range(50))\n",
    "\n",
    "    # block until all tasks are done\n",
    "    q.join()\n",
    "    \n",
    "    # Tell all our workers to stop\n",
    "    for i in range(50):\n",
    "        q.put('break')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in data frame\n",
    "\n",
    "# Adding headers\n",
    "results = [['Name','Price','Price per Liter']] + r\n",
    "\n",
    "# Convert to DF\n",
    "beer_df = pd.DataFrame(results[1:],columns=results[0])\n",
    "\n",
    "# Write dataframe to csv file\n",
    "beer_df.to_csv('Beer_Prices.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
